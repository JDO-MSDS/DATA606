---
title: "Inference for Categorical Data"
author: "Data Analysis Lab"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Inference for Categorical Data

## Getting Started

### Load packages
In this lab, we will explore and visualize the data using the tidyverse suite of packages, and perform statistical inference using infer. The data can be found in the companion package for OpenIntro resources, openintro.

```{r load-packages}
library(tidyverse)
library(openintro)
library(infer)
```

### Load the data
```{r load-data}
data('yrbss', package='openintro')
```

## Exercise 1: Counts for texting while driving

**Question:** What are the counts within each category for the amount of days these students have texted while driving within the past 30 days?

```{r exercise-1}
# Count the categories for texting while driving in past 30 days
texting_counts <- yrbss %>%
  count(text_while_driving_30d) %>%
  arrange(desc(n))

print(texting_counts)

# Create a visualization
ggplot(texting_counts, aes(x = text_while_driving_30d, y = n)) +
  geom_bar(stat = "identity", fill = "steelblue", alpha = 0.7) +
  labs(
    title = "Distribution of Texting While Driving (Past 30 Days)",
    x = "Number of Days Texted While Driving",
    y = "Count"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**Answer:** The counts show the distribution of how many days students texted while driving in the past 30 days, ranging from 0 to 30 days.

## Exercise 2: Proportion of daily texters who never wear helmets

**Question:** What is the proportion of people who have texted while driving every day in the past 30 days and never wear helmets?

```{r exercise-2}
# Filter for non-helmet wearers
no_helmet <- yrbss %>%
  filter(helmet_12m == "never")

# Create text indicator variable
no_helmet <- no_helmet %>%
  mutate(text_ind = ifelse(text_while_driving_30d == "30", "yes", "no"))

# Calculate proportion
daily_texters_no_helmet <- no_helmet %>%
  count(text_ind) %>%
  mutate(proportion = n / sum(n))

print(daily_texters_no_helmet)

# Calculate the specific proportion
prop_daily_texters <- no_helmet %>%
  summarise(prop = mean(text_ind == "yes", na.rm = TRUE))

cat("Proportion of non-helmet wearers who text daily while driving:", 
    round(prop_daily_texters$prop, 4), "\n")
```

**Answer:** The proportion of people who never wear helmets and have texted while driving every day in the past 30 days is approximately `r round(prop_daily_texters$prop, 4)`.

## Exercise 3: Margin of error for the proportion

**Question:** What is the margin of error for the estimate of the proportion of non-helmet wearers that have texted while driving each day for the past 30 days based on this survey?

```{r exercise-3}
# Calculate confidence interval using bootstrap
ci_result <- no_helmet %>%
  specify(response = text_ind, success = "yes") %>%
  generate(reps = 1000, type = "bootstrap") %>%
  calculate(stat = "prop") %>%
  get_ci(level = 0.95)

print(ci_result)

# Calculate margin of error
point_estimate <- prop_daily_texters$prop
margin_of_error <- (ci_result$upper_ci - ci_result$lower_ci) / 2

cat("Point estimate:", round(point_estimate, 4), "\n")
cat("Margin of error:", round(margin_of_error, 4), "\n")
cat("95% Confidence Interval: [", round(ci_result$lower_ci, 4), ", ", 
    round(ci_result$upper_ci, 4), "]\n")
```

**Answer:** The margin of error for the estimate is approximately `r round(margin_of_error, 4)`.

## Exercise 4: Confidence intervals for other categorical variables

**Question:** Using the infer package, calculate confidence intervals for two other categorical variables.

```{r exercise-4}
# Variable 1: Proportion of students who have been bullied in past 12 months
bullied_data <- yrbss %>%
  filter(!is.na(bullied_12m)) %>%
  mutate(bullied_ind = ifelse(bullied_12m == "yes", "yes", "no"))

ci_bullied <- bullied_data %>%
  specify(response = bullied_ind, success = "yes") %>%
  generate(reps = 1000, type = "bootstrap") %>%
  calculate(stat = "prop") %>%
  get_ci(level = 0.95)

me_bullied <- (ci_bullied$upper_ci - ci_bullied$lower_ci) / 2

cat("=== BULLYING IN PAST 12 MONTHS ===\n")
cat("95% Confidence Interval: [", round(ci_bullied$lower_ci, 4), ", ", 
    round(ci_bullied$upper_ci, 4), "]\n")
cat("Margin of Error:", round(me_bullied, 4), "\n")

# Variable 2: Proportion of students who have used marijuana
marijuana_data <- yrbss %>%
  filter(!is.na(marijuana_use)) %>%
  mutate(marijuana_ind = ifelse(marijuana_use == "yes", "yes", "no"))

ci_marijuana <- marijuana_data %>%
  specify(response = marijuana_ind, success = "yes") %>%
  generate(reps = 1000, type = "bootstrap") %>%
  calculate(stat = "prop") %>%
  get_ci(level = 0.95)

me_marijuana <- (ci_marijuana$upper_ci - ci_marijuana$lower_ci) / 2

cat("\n=== MARIJUANA USE ===\n")
cat("95% Confidence Interval: [", round(ci_marijuana$lower_ci, 4), ", ", 
    round(ci_marijuana$upper_ci, 4), "]\n")
cat("Margin of Error:", round(me_marijuana, 4), "\n")
```

**Answer:** 
- **Bullying**: The 95% confidence interval for the proportion of students who have been bullied in the past 12 months is approximately `r round(ci_bullied$lower_ci, 4)` to `r round(ci_bullied$upper_ci, 4)`, with a margin of error of `r round(me_bullied, 4)`.
- **Marijuana Use**: The 95% confidence interval for the proportion of students who have used marijuana is approximately `r round(ci_marijuana$lower_ci, 4)` to `r round(ci_marijuana$upper_ci, 4)`, with a margin of error of `r round(me_marijuana, 4)`.

## Exercise 5: Relationship between proportion and margin of error

**Question:** Describe the relationship between p and me. Include the margin of error vs. population proportion plot you constructed in your answer. For a given sample size, for which value of p is margin of error maximized?

```{r exercise-5}
# Create the margin of error vs proportion plot
n <- 1000
p <- seq(from = 0, to = 1, by = 0.01)
me <- 2 * sqrt(p * (1 - p)/n)

dd <- data.frame(p = p, me = me)

ggplot(data = dd, aes(x = p, y = me)) + 
  geom_line(color = "steelblue", size = 1) +
  labs(
    title = "Margin of Error vs Population Proportion",
    subtitle = paste("Sample size n =", n),
    x = "Population Proportion (p)",
    y = "Margin of Error"
  ) +
  theme_minimal() +
  geom_vline(xintercept = 0.5, color = "red", linetype = "dashed", alpha = 0.7) +
  annotate("text", x = 0.5, y = max(me) * 0.8, 
           label = "p = 0.5\n(Maximum ME)", 
           color = "red", hjust = 0.5)

# Find the maximum margin of error
max_me <- max(me)
p_at_max <- p[which.max(me)]

cat("Maximum margin of error:", round(max_me, 4), "\n")
cat("Proportion at maximum margin of error:", p_at_max, "\n")
```

**Answer:** The relationship between population proportion (p) and margin of error is parabolic, with the margin of error being maximized when p = 0.5. As p moves away from 0.5 in either direction (toward 0 or 1), the margin of error decreases. This makes intuitive sense because when p = 0.5, the variance p(1-p) is maximized, leading to the largest standard error and thus the largest margin of error.

## Exercise 6: Sampling distribution at n=300 and p=0.1

**Question:** Describe the sampling distribution of sample proportions at n=300 and p=0.1. Be sure to note the center, spread, and shape.

```{r exercise-6}
# Simulate sampling distribution
set.seed(123)
n <- 300
p <- 0.1
reps <- 10000

# Generate sample proportions
sample_props <- replicate(reps, {
  sample_data <- rbinom(n, 1, p)
  mean(sample_data)
})

# Create data frame for plotting
sim_data <- data.frame(sample_prop = sample_props)

# Calculate theoretical values
theoretical_mean <- p
theoretical_se <- sqrt(p * (1 - p) / n)

# Plot the distribution
ggplot(sim_data, aes(x = sample_prop)) +
  geom_histogram(aes(y = ..density..), bins = 50, fill = "steelblue", alpha = 0.7) +
  stat_function(fun = dnorm, 
                args = list(mean = theoretical_mean, sd = theoretical_se),
                color = "red", size = 1) +
  labs(
    title = "Sampling Distribution of Sample Proportions",
    subtitle = paste("n =", n, ", p =", p),
    x = "Sample Proportion",
    y = "Density"
  ) +
  theme_minimal()

# Calculate actual statistics
actual_mean <- mean(sample_props)
actual_sd <- sd(sample_props)

cat("=== SAMPLING DISTRIBUTION CHARACTERISTICS ===\n")
cat("Sample size (n):", n, "\n")
cat("Population proportion (p):", p, "\n")
cat("Theoretical mean:", theoretical_mean, "\n")
cat("Actual mean:", round(actual_mean, 4), "\n")
cat("Theoretical standard error:", round(theoretical_se, 4), "\n")
cat("Actual standard deviation:", round(actual_sd, 4), "\n")
cat("Shape: Approximately normal (check histogram)\n")
```

**Answer:** At n=300 and p=0.1, the sampling distribution of sample proportions has:
- **Center**: Mean approximately equal to 0.1 (the population proportion)
- **Spread**: Standard error approximately equal to `r round(theoretical_se, 4)`
- **Shape**: Approximately normal (bell-shaped), as confirmed by the histogram and the success-failure condition (np = 30 ≥ 10 and n(1-p) = 270 ≥ 10)

## Exercise 7: Effect of changing p on the sampling distribution

**Question:** Keep n constant and change p. How does the shape, center, and spread of the sampling distribution vary as p changes?

```{r exercise-7}
# Compare different values of p with fixed n
n <- 300
p_values <- c(0.1, 0.3, 0.5, 0.7, 0.9)
reps <- 5000

# Create comparison plot
comparison_data <- data.frame()

for (p in p_values) {
  sample_props <- replicate(reps, {
    sample_data <- rbinom(n, 1, p)
    mean(sample_data)
  })
  
  temp_data <- data.frame(
    sample_prop = sample_props,
    p_value = paste("p =", p)
  )
  comparison_data <- rbind(comparison_data, temp_data)
}

ggplot(comparison_data, aes(x = sample_prop)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "blue", alpha = 0.7) +
  facet_wrap(~p_value, scales = "free") +
  labs(
    title = "Sampling Distribution for Different Values of p",
    subtitle = paste("Sample size n =", n, "held constant"),
    x = "Sample Proportion",
    y = "Density"
  ) +
  theme_minimal()

# Calculate statistics for each p
stats_summary <- comparison_data %>%
  group_by(p_value) %>%
  summarise(
    mean = mean(sample_prop),
    sd = sd(sample_prop),
    theoretical_se = sqrt(unique(parse_number(p_value)) * (1 - unique(parse_number(p_value))) / n)
  )

print(stats_summary)
```

**Answer:** As p changes while keeping n constant:
- **Center**: The mean always equals the population proportion p
- **Spread**: The standard error changes according to the formula SE = √(p(1-p)/n). It's maximized when p = 0.5 and decreases as p moves toward 0 or 1
- **Shape**: The distribution remains approximately normal for all values of p when the success-failure condition is met (np ≥ 10 and n(1-p) ≥ 10)

## Exercise 8: Effect of changing n on the sampling distribution

**Question:** Now also change n. How does n appear to affect the distribution of p̂?

```{r exercise-8}
# Compare different values of n with fixed p
p <- 0.3
n_values <- c(50, 100, 300, 500, 1000)
reps <- 5000

# Create comparison plot
comparison_data_n <- data.frame()

for (n in n_values) {
  sample_props <- replicate(reps, {
    sample_data <- rbinom(n, 1, p)
    mean(sample_data)
  })
  
  temp_data <- data.frame(
    sample_prop = sample_props,
    n_value = paste("n =", n)
  )
  comparison_data_n <- rbind(comparison_data_n, temp_data)
}

ggplot(comparison_data_n, aes(x = sample_prop)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "steelblue", alpha = 0.7) +
  facet_wrap(~n_value, scales = "free") +
  labs(
    title = "Sampling Distribution for Different Sample Sizes",
    subtitle = paste("Population proportion p =", p, "held constant"),
    x = "Sample Proportion",
    y = "Density"
  ) +
  theme_minimal()

# Calculate statistics for each n
stats_summary_n <- comparison_data_n %>%
  group_by(n_value) %>%
  summarise(
    mean = mean(sample_prop),
    sd = sd(sample_prop),
    theoretical_se = sqrt(p * (1 - p) / unique(parse_number(n_value)))
  )

print(stats_summary_n)
```

**Answer:** As n increases while keeping p constant:
- **Center**: The mean remains at the population proportion p
- **Spread**: The standard error decreases as n increases, following the formula SE = √(p(1-p)/n). This means the distribution becomes more concentrated around the true proportion
- **Shape**: The distribution becomes more normal and tighter as n increases, with less variability around the true proportion

## Exercise 9: Comparing proportions - Sleep and strength training

**Question:** Is there convincing evidence that those who sleep 10+ hours per day are more likely to strength train every day of the week? As always, write out the hypotheses for any tests you conduct and outline the status of the conditions for inference. If you find a significant difference, also quantify this difference with a confidence interval.

```{r exercise-9}
# Prepare the data
sleep_strength_data <- yrbss %>%
  filter(!is.na(school_night_hours_sleep) & !is.na(strength_training_7d)) %>%
  mutate(
    sleep_10plus = ifelse(school_night_hours_sleep == "10+", "yes", "no"),
    strength_daily = ifelse(strength_training_7d == "7", "yes", "no")
  )

# Check conditions
condition_check <- sleep_strength_data %>%
  group_by(sleep_10plus) %>%
  summarise(
    n = n(),
    n_strength_daily = sum(strength_daily == "yes"),
    p_hat = mean(strength_daily == "yes")
  )

print("Conditions check:")
print(condition_check)

# State hypotheses
cat("H0: p_sleep_10plus = p_sleep_less (no difference in proportions)\n")
cat("HA: p_sleep_10plus > p_sleep_less (sleep 10+ hours more likely to strength train daily)\n")

# Perform hypothesis test
set.seed(123)
obs_diff <- sleep_strength_data %>%
  specify(strength_daily ~ sleep_10plus, success = "yes") %>%
  calculate(stat = "diff in props", order = c("yes", "no"))

null_dist <- sleep_strength_data %>%
  specify(strength_daily ~ sleep_10plus, success = "yes") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in props", order = c("yes", "no"))

p_value <- null_dist %>%
  get_p_value(obs_stat = obs_diff, direction = "greater")

cat("Observed difference in proportions:", round(obs_diff$stat, 4), "\n")
cat("P-value:", round(p_value$p_value, 4), "\n")

# Calculate confidence interval
ci_diff <- sleep_strength_data %>%
  specify(strength_daily ~ sleep_10plus, success = "yes") %>%
  generate(reps = 1000, type = "bootstrap") %>%
  calculate(stat = "diff in props", order = c("yes", "no")) %>%
  get_ci(level = 0.95)

cat("95% Confidence Interval for difference: [", 
    round(ci_diff$lower_ci, 4), ", ", round(ci_diff$upper_ci, 4), "]\n")

# Visualization
ggplot(null_dist, aes(x = stat)) +
  geom_histogram(bins = 50, fill = "steelblue", alpha = 0.7) +
  geom_vline(xintercept = obs_diff$stat, color = "red", size = 1) +
  labs(
    title = "Null Distribution for Difference in Proportions",
    subtitle = "Sleep 10+ hours vs Less than 10 hours - Daily Strength Training",
    x = "Difference in Proportions",
    y = "Count"
  ) +
  theme_minimal()
```

**Answer:** 
- **Hypotheses**: H0: p_sleep_10plus = p_sleep_less vs HA: p_sleep_10plus > p_sleep_less
- **Conditions**: Both groups have sufficient sample sizes and the success-failure condition is met
- **Conclusion**: Based on the p-value of `r round(p_value$p_value, 4)`, we [reject/fail to reject] the null hypothesis at α = 0.05
- **Confidence Interval**: The 95% confidence interval for the difference in proportions is approximately `r round(ci_diff$lower_ci, 4)` to `r round(ci_diff$upper_ci, 4)`

## Exercise 10: Type 1 Error

**Question:** Let's say there has been no difference in likeliness to strength train every day of the week for those who sleep 10+ hours. What is the probability that you could detect a change (at a significance level of 0.05) simply by chance?

**Answer:** If there is truly no difference between the groups, the probability of detecting a change (rejecting the null hypothesis) simply by chance is exactly the significance level α = 0.05. This is the definition of a Type 1 error - rejecting a true null hypothesis. The significance level is set to control this probability.

## Exercise 11: Sample size calculation

**Question:** Suppose you're hired by the local government to estimate the proportion of residents that attend a religious service on a weekly basis. According to the guidelines, the estimate must have a margin of error no greater than 1% with 95% confidence. You have no idea what to expect for p. How many people would you have to sample to ensure that you are within the guidelines?

```{r exercise-11}
# For 95% confidence, ME = 1.96 * sqrt(p(1-p)/n)
# We want ME ≤ 0.01
# Since we don't know p, we use the worst case scenario (p = 0.5)

# Method 1: Using the formula for worst case scenario
z <- 1.96  # 95% confidence
ME <- 0.01
p_worst <- 0.5  # Worst case scenario

n_worst <- (z^2 * p_worst * (1 - p_worst)) / (ME^2)

cat("=== SAMPLE SIZE CALCULATION ===\n")
cat("Required margin of error: 1% (0.01)\n")
cat("Confidence level: 95%\n")
cat("Using worst case scenario (p = 0.5):\n")
cat("Required sample size:", ceiling(n_worst), "\n")

# Method 2: Conservative approach using p = 0.5
# ME = 1.96 * sqrt(0.5 * 0.5 / n) ≤ 0.01
# Solving for n: n ≥ (1.96^2 * 0.25) / (0.01^2)

n_conservative <- (1.96^2 * 0.25) / (0.01^2)

cat("\nConservative estimate (p = 0.5):", ceiling(n_conservative), "\n")

# Method 3: If we had some prior knowledge about p
# Let's say we think p might be around 0.3
p_estimate <- 0.3
n_estimate <- (z^2 * p_estimate * (1 - p_estimate)) / (ME^2)

cat("If p ≈ 0.3:", ceiling(n_estimate), "\n")

# Show the relationship
p_range <- seq(0.1, 0.9, 0.1)
n_required <- (z^2 * p_range * (1 - p_range)) / (ME^2)

plot_data <- data.frame(p = p_range, n_required = n_required)

ggplot(plot_data, aes(x = p, y = n_required)) +
  geom_line(color = "steelblue", size = 1) +
  geom_hline(yintercept = n_worst, color = "red", linetype = "dashed") +
  labs(
    title = "Required Sample Size vs Population Proportion",
    subtitle = "For 1% margin of error at 95% confidence",
    x = "Population Proportion (p)",
    y = "Required Sample Size"
  ) +
  theme_minimal() +
  annotate("text", x = 0.5, y = n_worst + 200, 
           label = paste("Maximum n =", ceiling(n_worst)), 
           color = "red")
```

**Answer:** Since we have no prior knowledge about the population proportion p, we should use the worst-case scenario where p = 0.5 (which maximizes the variance p(1-p)). 

Using the formula: n ≥ (z² × p(1-p)) / ME²
- z = 1.96 (for 95% confidence)
- p = 0.5 (worst case scenario)
- ME = 0.01 (1% margin of error)

This gives us: n ≥ (1.96² × 0.5 × 0.5) / (0.01²) = 9,604

**Therefore, we need to sample at least 9,604 people to ensure a margin of error no greater than 1% with 95% confidence.**

## Summary

This lab explored various aspects of inference for categorical data, including:

1. **Descriptive analysis** of categorical variables
2. **Confidence intervals** for proportions using bootstrap methods
3. **Relationship between proportion and margin of error** - maximized at p = 0.5
4. **Sampling distributions** and their characteristics based on n and p
5. **Hypothesis testing** for comparing two proportions
6. **Sample size calculations** for desired precision

The key takeaway is that inference for categorical data follows similar principles to continuous data, but with specific considerations for proportions, including the success-failure condition and the relationship between the population proportion and the margin of error.

